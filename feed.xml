<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://tobbyxy.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tobbyxy.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-19T18:50:51+00:00</updated><id>https://tobbyxy.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">True understanding is not cheap</title><link href="https://tobbyxy.github.io/blog/2025/True-Understanding-is-not-cheap/" rel="alternate" type="text/html" title="True understanding is not cheap"/><published>2025-04-06T20:01:00+00:00</published><updated>2025-04-06T20:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2025/True-Understanding-is-not-cheap</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2025/True-Understanding-is-not-cheap/"><![CDATA[<p>True Understanding Looking for the crux or meat of what you’re trying to achieve. Zooming in and out constantly and not letting your short term goals distract your long term vision. Most of the experts I’ve seen always have an idea of what they want to achieve. Problem solving is easier when you understand. True understanding is not easy. I always catch my self looking for true understanding, merely memorizing definitions, reciting terms is not true understanding. when do you truly achieve understanding? I don’t know, Here is what I think; when you can rederive a concept from multiple starting point (I heard this from somewhere). When you are not bound by definitions and maybe when you have alternative explanations (maybe even contradicting).</p> <p>Understanding takes time and patience. so you sleep with the problems and wake up with new or sometimes clearer definitions and ideas. True understanding requires understanding a system so you take the most optimal path to solving the presented problems.</p>]]></content><author><name></name></author><category term="post"/><category term="thoughts"/><summary type="html"><![CDATA[True Understanding Looking for the crux or meat of what you’re trying to achieve. Zooming in and out constantly and not letting your short term goals distract your long term vision. Most of the experts I’ve seen always have an idea of what they want to achieve. Problem solving is easier when you understand. True understanding is not easy. I always catch my self looking for true understanding, merely memorizing definitions, reciting terms is not true understanding. when do you truly achieve understanding? I don’t know, Here is what I think; when you can rederive a concept from multiple starting point (I heard this from somewhere). When you are not bound by definitions and maybe when you have alternative explanations (maybe even contradicting).]]></summary></entry><entry><title type="html">What a p value really means?</title><link href="https://tobbyxy.github.io/blog/2024/what-p-values-means-really/" rel="alternate" type="text/html" title="What a p value really means?"/><published>2024-12-05T20:01:00+00:00</published><updated>2024-12-05T20:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/what-p-values-means-really</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/what-p-values-means-really/"><![CDATA[<p>what a pvalue really means?</p> <p>Correct understanding of p value is not trivial, and the interpretation of p values is mostly misunderstood. I find myself having to go back to terminologies and basics to properly interprete statistically significant findings.</p> <p>Terminologies first-</p> <p>sample: an experiment or data we collect to say something about a population. it is usually used to make inference(conclusion) about a population. ideally should be a good representation of the population population: The set of all possible data we can collect for a given observation (e.g height) statistics: measures calculated from the sample, used to estimate population parameters Test statistics: value calculated from the sample data that is compared to the critical value to determine whether to reject the null hypothesis. Null Hypothesis: A statement asserting that there is no (effect, difference, relationship) in the variables being studied. e.g “there is no differece in average height between two groups” Critical region: is the region or range of values which we preset that leads to rejection of the null hypothesis alpha: significance level, is the probability of rejecting the null hypothesis when it is true (Type I error)</p> <p>Example Next- boys are known to have a mean weight of 85 pounds. There is a complaint about boys living in iowa to be underfed. Data is collected for evidence, n = 25 (of the same age) are weighed and found to have a mean weight of 80.94 pounds. It is known that the population standard deviation is 11.6 pounds.</p> <p>In this example we can calculate the Z statistics, and use it to test our null hypothesis.</p> <p>z = -1.75</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w">

</span><span class="c1"># Set parameters</span><span class="w">
</span><span class="n">mu0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c1"># Null hypothesis mean</span><span class="w">
</span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">  </span><span class="c1"># Standard deviation</span><span class="w">
</span><span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">  </span><span class="c1"># Significance level</span><span class="w">
</span><span class="n">z_stat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-1.75</span><span class="w">  </span><span class="c1"># Observed z-statistic</span><span class="w">

</span><span class="c1"># Calculate critical values and p-value</span><span class="w">
</span><span class="n">z_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">qnorm</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">p_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">pnorm</span><span class="p">(</span><span class="n">z_stat</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create data for plotting</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-4</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span><span class="w">
</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create the plot</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_line</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_area</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">subset</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="o">-</span><span class="n">z_crit</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">z_crit</span><span class="p">),</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="o">-</span><span class="n">z_crit</span><span class="p">,</span><span class="w"> </span><span class="n">z_crit</span><span class="p">),</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"dashed"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">z_stat</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"solid"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">z_crit</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Critical\nRegion"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">z_crit</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Critical\nRegion"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">z_stat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="s2">"z ="</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">z_stat</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">annotate</span><span class="p">(</span><span class="s2">"text"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-3</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="s2">"p-value ="</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">p_value</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">)),</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Standard Normal Distribution with Critical Regions"</span><span class="p">,</span><span class="w">
       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Z-score"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Density"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span></code></pre></div></div> <p>The critical region to reject the null hypothesis at the alpha level 0.05 if z &lt; -1.645. Therefore we reject the Null hypothesis. using the critical region approach. We can also calculate the probability of seeing a new test statistics as extreme( or more extreme)as our observed test statistics, if the null hypothesis was true. p(z &lt; -1.75), which is equal to 0.0401.This probability is called the P-value.</p> <p>It is the probability that depends on the distribution of the test statistics.it tells us whether or not (there is an effect/difference/relationship). It is not the probability of the null hypothesis being true nor does it say anything about size (how large or small) the effect will be.</p> <p>P-value is the smallest alpha value that will cause us to reject the null hypothesis. if the p value is less than alpha, we reject the null hypothesis and if greater than alpha, we fail to reject the hypothesis.</p> <p>While this example is trivial, care must be taken when interpreting P-values. A result can be statistically significant without having any real world implication (practical signficance). A good domain knowledge is necessary to assert the practicality of statistically significant results, other potential forms of error (selection, measurement) must be considered.</p> <p>A large sample size and low variability in the data can also produce very low p values whose effect size is negligible. while small sample size might fail to detect meaningful effects(Type II error). Achieving statistical significance does not eliminate all forms of bias in a study.</p> <p>In conclusion, we should be careful of wrongful interpretation of research findings by merely overemphasing on low P-values, which might lead to misleading conclusion and oversimlification of complex research.</p>]]></content><author><name></name></author><category term="post"/><category term="stats"/><category term="maths"/><summary type="html"><![CDATA[what a pvalue really means?]]></summary></entry><entry><title type="html">What I’m taking into 2025</title><link href="https://tobbyxy.github.io/blog/2024/what-I-m-taking-into-2025/" rel="alternate" type="text/html" title="What I’m taking into 2025"/><published>2024-12-05T20:01:00+00:00</published><updated>2024-12-05T20:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/what-I%E2%80%99m-taking-into-2025</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/what-I-m-taking-into-2025/"><![CDATA[<p>Prioritizing physical and mental health Healthy eating and better sleep schedule Making time for hobbies , friendship and relationships Working long hours doesn’t mean productive Become a domain knowledge expert, Getting better at my craft Good communication, writing, networking. The best bioinformaticians are the ones who know how to frame the right question to ask, they always have a deeper domain knowledge</p> <p>See 🎯 Ming “Tommy” Tang blog</p> <p>I tell myself around biologist, I’m a statistician and around statisticians, I’m a biologist.</p> <p>Getting familiar with AI tools The best innovation we’ve seen in the past decade came from computers (software), the future is no different. Almost every now and then try to use some new AI tool. Everyone knows ChatGPT, have you tried cursor or perplexity?</p> <p>Cursor for coding, Perplexity for search</p> <p>Most of your big breaks are just a network away from you. Networking/Mentors work, if you see someone you admire who has gone the path you wish to go, reach out and form the connection. The smartest people I know are humble, they share their time and ideas freely. If you can provide value and you’re not well compensated consider changing your environment. An umbrella is not useful until there’s a rainfall. Service. Consider doing for others what you’ll like to be done for yourself. In putting others first, you help yourself.</p> <p>Wishing you a happy holiday.</p> <p>See you soon!</p>]]></content><author><name></name></author><category term="post"/><category term="thoughts"/><summary type="html"><![CDATA[Prioritizing physical and mental health Healthy eating and better sleep schedule Making time for hobbies , friendship and relationships Working long hours doesn’t mean productive Become a domain knowledge expert, Getting better at my craft Good communication, writing, networking. The best bioinformaticians are the ones who know how to frame the right question to ask, they always have a deeper domain knowledge]]></summary></entry><entry><title type="html">What Markov can teach us about life</title><link href="https://tobbyxy.github.io/blog/2024/What-Markov-can-teach-us-about-life/" rel="alternate" type="text/html" title="What Markov can teach us about life"/><published>2024-12-04T20:01:00+00:00</published><updated>2024-12-04T20:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/What-Markov-can-teach-us-about-life</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/What-Markov-can-teach-us-about-life/"><![CDATA[<p>Markov is a Russian mathematician that discovered the famous Markov model - we’ll avoid the maths for simplicity sake. The model says : The future is independent of the past given the present. Where we end up is determined by where we are at now and not where we’ve been.</p> <p>It struck me that the model has more than a mathematical utility. As a consequence of this model’s assumption we can hold solace in the fact that no matter what we’ve been through or how far we’ve gone wrong, we can - and should change course to determine our future. Our past is not a determinant of where we can go. We can and should continually reinvent ourselves.</p> <p>One might ask shouldn’t we learn from our past? Should we just forget all that has happened? One way to answer that is our present is a culmination of our past - where we are currently is as a result of our past decisions. The past is data, if we learn from data, we improve our future decision. But we must not hold on to the past. People spend too much time dwelling there, and it seems to not be a good predictor of the future. While useful, we must ensure to be in the present.</p> <p>Another argument for the past is its utility in gratitude. It’s thanksgiving season, one of the most asked questions is what are you grateful for? One can draw from positive moments of the past that makes us hope for the future. Because it was good in the past, it can be better in the future. We can cultivate gratitude from the past that makes the present/future more meaningful and livable. If we choose to remember past moments, let it be stories and memories that displays hope despite today’s challenges.</p> <p>Markov leaves us with an empowering statement, you can always change course - once you decide to at different stages of your life whether young or old. Above all, be present, for that’s what most important to your future.</p>]]></content><author><name></name></author><category term="post"/><category term="philosoophy"/><category term="maths"/><summary type="html"><![CDATA[Markov is a Russian mathematician that discovered the famous Markov model - we’ll avoid the maths for simplicity sake. The model says : The future is independent of the past given the present. Where we end up is determined by where we are at now and not where we’ve been.]]></summary></entry><entry><title type="html">Learning Bioinformatics in 2024</title><link href="https://tobbyxy.github.io/blog/2024/Learning-Bioinformatics-in-2024/" rel="alternate" type="text/html" title="Learning Bioinformatics in 2024"/><published>2024-08-22T20:01:00+00:00</published><updated>2024-08-22T20:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/Learning-Bioinformatics-in-2024</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/Learning-Bioinformatics-in-2024/"><![CDATA[<p>This is an update from my previous article Learning Bioinformatics in <a href="https://www.linkedin.com/pulse/learning-bioinformatics-2023-step-by-step-guide-tobi-aminu/?trackingId=bw2S8rhEQ7ulbnKLtorkXA%3D%3D">2023</a></p> <p>Everything still stands, learning the foundation cannot be replaced. As an enthusiast I am interested in how the learning is changing as technology advances, It is also a good way to document for myself the evolution of bioinformatics learning.</p> <p>I started working in a different aspect of biology, infectious disease and I’m suprised the amount of opportunities available for computational work. but the solutions are far fetching, not ubuiquitious as the problems.</p> <h2 id="how-can-we-leverage-technological-advancement-to-enhance-computational-biology-learning">How can we leverage technological advancement to enhance computational biology learning?</h2> <h3 id="use-aichat-bot-to-enhance-learning">Use AI/Chat bot to enhance learning.</h3> <p>Few years ago, i will have to spend hours on google and stackoverflow to solve my coding problems. Now theres chatgpt, github copilot, large language models are everywhere, It makes no sense to spend hours on basic mundane task, this frees up space for creative work.</p> <p>You have to use it, adapt with it, change style</p> <p>Word of caution, this models make mistakes and perform poorly on creative or novel work. There are good for brainstorming and initial idead generations.</p> <h3 id="use-a-workflow-manager">Use a workflow manager</h3> <p>When I started out, I remember writing the same command individually and saving my output. Then after a few months i try to remember what code I ran, sometimes I’m lucky enough to have written it down, other times no. I had to run the command again, sometimes the result could change.</p> <p>workflow managers like snakemake, nextflow help in reproducibility and automation. Now i have a history of the codes i ran, I also don’t have to run individual commands any more.</p> <h3 id="project-organization-and-document-code">Project Organization and document code</h3> <p>Workflow management relates directly project organization. A good project organization, is the one you can refer to in 10, 20 years time. It is a foundational practice that we “computational people” ignore and I’ll always take the oppourtunity to resound it again.</p> <h3 id="worry-less-about-what-computer-i-use">worry less about what computer I use</h3> <p>Back in the day, I spent to much time than I should have about what laptop to get for my work. Now i just connect to a high performance computing cluster. With the amount of compute power available and cloud computing advancement. The Computer I use is one less problem. Even storage, the compute power and storage available on the cloud is enormous.</p> <p>I’m still learning and I’m still documenting.</p>]]></content><author><name></name></author><category term="post"/><category term="Learn"/><summary type="html"><![CDATA[This is an update from my previous article Learning Bioinformatics in 2023]]></summary></entry><entry><title type="html">Think Python by Allen Downey?</title><link href="https://tobbyxy.github.io/blog/2024/Think-Python/" rel="alternate" type="text/html" title="Think Python by Allen Downey?"/><published>2024-07-03T21:01:00+00:00</published><updated>2024-07-03T21:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/Think-Python</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/Think-Python/"><![CDATA[<h1 id="list">List</h1> <h2 id="exercise">Exercise</h2> <p>Two words are anagrams if you can rearrange the letters from one to spell the other. For example, tops is an anagram of stop. One way to check whether two words are anagrams is to sort the letters in both words. If the lists of sorted letters are the same, the words are anagrams. Write a function called is_anagram that takes two strings and returns True if they are anagrams. Using your function and the word list, find all the anagrams of takes.</p> <pre><code class="language-Python">def is_anagram(s1, s2):
    return sorted(s1) == sorted(s2)
</code></pre> <p>A palindrome is a word that is spelled the same backward and forward, like “noon” and “rotator”. Write a function called is_palindrome that takes a string argument and returns True if it is a palindrome and False otherwise</p> <pre><code class="language-Python">def is_palindrome(s):
    return s == s[::-1]
def is_palindrome(s):
    return s == ''.join(reversed(s))
</code></pre> <h1 id="dictionary">Dictionary</h1> <h2 id="exercise-1">Exercise</h2> <p>“Why do keys in Python dictionaries have to be hashable?”</p> <p>Dictionaries have a method called get that takes a key and a default value. If the key appears in the dictionary, get returns the corresponding value; otherwise it returns the default value. For example, here’s a dictionary that maps from the letters in a string to the number of times they appear.</p> <p>Use get to write a more concise version of value_counts. You should be able to eliminate the if statement.</p> <pre><code class="language-Python">def value_counts(string):
    counter = {}
    for letter in string:
        counter[letter] = counter.get(letter, 0) + 1
    return counter
</code></pre> <p>Write a function named has_duplicates that takes a sequence – like a list or string – as a parameter and returns True if there is any element that appears in the sequence more than once.</p> <pre><code class="language-Python">def has_duplicates(s):
    return len(set(s)) &lt; len(s)
#example
has_duplicates('hello')
</code></pre> <p>Write function called find_repeats that takes a dictionary that maps from each key to a counter, like the result from value_counts. It should loop through the dictionary and return a list of keys that have counts greater than 1. You can use the following outline to get started.</p> <pre><code class="language-Python">def find_repeated(counter):
    return [item for item in counter if counter[item] == 1]
</code></pre>]]></content><author><name></name></author><category term="projects"/><category term="Python"/><summary type="html"><![CDATA[List]]></summary></entry><entry><title type="html">A Network Analysis of Game of Thrones</title><link href="https://tobbyxy.github.io/blog/2024/Network-Analysis-of-Game-Of-Thrones/" rel="alternate" type="text/html" title="A Network Analysis of Game of Thrones"/><published>2024-06-14T12:57:00+00:00</published><updated>2024-06-14T12:57:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/Network-Analysis-of-Game-Of-Thrones</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/Network-Analysis-of-Game-Of-Thrones/"><![CDATA[<p>Network analysis, graphs, page rank, evolution are all interesting concepts I explore in this fun project. Networks evolve as seen in game of thrones characters, Important nodes become less important as we go further in books.</p> <ol> <li>Winter is Coming. If you haven’t heard of Game of Thrones, then you must be really good at hiding. Game of Thrones is the hugely popular television series by HBO based on the (also) hugely popular book series A Song of Ice and Fire by George R.R. Martin. In this notebook, we will analyze the co-occurrence network of the characters in the Game of Thrones books. Here, two characters are considered to co-occur if their names appear in the vicinity of 15 words from one another in the books.</li> </ol> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/Network-Analysis-of-game-of-thrones.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="fun"/><category term="project"/><category term="jupyter"/><category term="Datacamp"/><summary type="html"><![CDATA[Data Camp Fun Project]]></summary></entry><entry><title type="html">Who is Drunk, and When in Ames, Iowa?</title><link href="https://tobbyxy.github.io/blog/2024/who-is-drunk/" rel="alternate" type="text/html" title="Who is Drunk, and When in Ames, Iowa?"/><published>2024-05-29T12:57:00+00:00</published><updated>2024-05-29T12:57:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/who-is-drunk</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/who-is-drunk/"><![CDATA[<p>This project was of interest to me because I’m currenlty in Ames, Iowa. It allows me to also practise my data science skills on past decision made. We are trying to answer the question: Was it a good decision to cancel the <a href="https://en.wikipedia.org/wiki/VEISHEA">VEISHEA</a></p> <p>From Wikipedia: “VEISHEA was an annual week-long celebration held each spring on the campus of Iowa State University in Ames, Iowa. The celebration featured an annual parade and many open-house demonstrations of the university facilities and departments. Campus organizations exhibited products, technologies, and held fundraisers for various charity groups. In addition, VEISHEA brought speakers, lecturers, and entertainers to Iowa State. […] VEISHEA was the largest student-run festival in the nation, bringing in tens of thousands of visitors to the campus each year.”</p> <p>This over 90-year tradition in Ames was terminated permanently after riots in 2014, where drunk celebrators flipped over multiple vehicles and tore light poles down. This was not the first incidence of violence and severe property damage in VEISHEA’s history. Did former President Leath make the right decision by canceling VEISHEA?</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/who_is_drunk_notebook.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="fun"/><category term="project"/><category term="jupyter"/><category term="Datacamp"/><summary type="html"><![CDATA[Data Camp Fun Project]]></summary></entry><entry><title type="html">Friends Don’t Let Friends</title><link href="https://tobbyxy.github.io/blog/2024/Friends-don't-let-Friends/" rel="alternate" type="text/html" title="Friends Don’t Let Friends"/><published>2024-05-28T15:09:00+00:00</published><updated>2024-05-28T15:09:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/Friends-don&apos;t-let-Friends</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/Friends-don&apos;t-let-Friends/"><![CDATA[<p>This is a series motivated by the popular friends don’t let friends in R. My goal is to rewrite the codes in python and explore the common visualization mistakes in python ecosystem.</p> <p>Let’s have fun: It is possible to have two groups with similar means but different distribution, be cautious about the type of visualisation you use when representing data. Alwaya double check.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">iqr</span>
<span class="kn">import</span> <span class="n">random</span>


<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="c1"># Normal distribution
</span><span class="n">group1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Log-normal distribution
</span><span class="n">meanlog</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">sdlog</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="p">(</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>
<span class="n">group2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">lognormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">meanlog</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sdlog</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">group1</span><span class="sh">'</span><span class="p">:</span> <span class="n">group1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">group2</span><span class="sh">'</span><span class="p">:</span> <span class="n">group2</span>
<span class="p">})</span>
<span class="n">groups_long</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">melt</span><span class="p">(</span><span class="n">var_name</span><span class="o">=</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">,</span> <span class="n">value_name</span><span class="o">=</span><span class="sh">'</span><span class="s">response</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <p>Using three statististical test and visualization, we can check if these two groups are different or not.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># T-test
</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">t_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="c1"># Wilcoxon rank-sum test (also known as Mann-Whitney U test)
</span><span class="n">wilcox_stat</span><span class="p">,</span> <span class="n">wilcox_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mannwhitneyu</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="c1"># Kolmogorov-Smirnov test
</span><span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ks_2samp</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">T-test p-value: </span><span class="si">{</span><span class="n">t_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Wilcoxon rank-sum test p-value: </span><span class="si">{</span><span class="n">wilcox_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Kolmogorov-Smirnov test p-value: </span><span class="si">{</span><span class="n">ks_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># T-test
</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">t_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="c1"># Wilcoxon rank-sum test (also known as Mann-Whitney U test)
</span><span class="n">wilcox_stat</span><span class="p">,</span> <span class="n">wilcox_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">mannwhitneyu</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="c1"># Kolmogorov-Smirnov test
</span><span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_p</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ks_2samp</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">T-test p-value: </span><span class="si">{</span><span class="n">t_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Wilcoxon rank-sum test p-value: </span><span class="si">{</span><span class="n">wilcox_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Kolmogorov-Smirnov test p-value: </span><span class="si">{</span><span class="n">ks_p</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Create a figure with 3 subplots in the same row
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Create scatter plot
</span><span class="n">sns</span><span class="p">.</span><span class="nf">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">response</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">groups_long</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="sh">'</span><span class="s">Accent</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Scatter Plot</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Perform and annotate Kolmogorov-Smirnov test
</span><span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_pval</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ks_2samp</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">annotate</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Kolmogorov-Smirnov p-value: </span><span class="si">{</span><span class="n">ks_pval</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="sh">'</span><span class="s">axes fraction</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Create box plot
</span><span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">response</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">groups_long</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="sh">'</span><span class="s">Accent</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Box Plot</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Perform and annotate Wilcoxon rank-sum test
</span><span class="n">wilcoxon_stat</span><span class="p">,</span> <span class="n">wilcoxon_pval</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ranksums</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">annotate</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Wilcoxon rank-sum p-value: </span><span class="si">{</span><span class="n">wilcoxon_pval</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="sh">'</span><span class="s">axes fraction</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Create bar plot
</span><span class="n">sns</span><span class="p">.</span><span class="nf">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">response</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">groups_long</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="sh">'</span><span class="s">Accent</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Bar Plot</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Perform and annotate t-test
</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">t_pval</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">annotate</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t-test p-value: </span><span class="si">{</span><span class="n">t_pval</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span> <span class="n">xycoords</span><span class="o">=</span><span class="sh">'</span><span class="s">axes fraction</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Show the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>

<span class="c1"># Save the figure as a PDF in the 'Figures' folder
</span><span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">Figures/mean_seperation.pdf</span><span class="sh">'</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">pdf</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/figures/mean_seperation-480.webp 480w,/assets/img/figures/mean_seperation-800.webp 800w,/assets/img/figures/mean_seperation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/figures/mean_seperation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="Data"/><category term="Viz"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[an example of a blog post with some code]]></summary></entry><entry><title type="html">Are you doing Enrichment Analysis Properly?</title><link href="https://tobbyxy.github.io/blog/2024/Enrichment-Analysis-properly/" rel="alternate" type="text/html" title="Are you doing Enrichment Analysis Properly?"/><published>2024-05-27T21:01:00+00:00</published><updated>2024-05-27T21:01:00+00:00</updated><id>https://tobbyxy.github.io/blog/2024/Enrichment-Analysis-properly</id><content type="html" xml:base="https://tobbyxy.github.io/blog/2024/Enrichment-Analysis-properly/"><![CDATA[<blockquote> <p>Enrichment analysis is common, but is it done properly?</p> </blockquote> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/enrichment_analysis-480.webp 480w,/assets/img/enrichment_analysis-800.webp 800w,/assets/img/enrichment_analysis-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/enrichment_analysis.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/enrichment_analysis-480.webp 480w,/assets/img/enrichment_analysis-800.webp 800w,/assets/img/enrichment_analysis-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/enrichment_analysis.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Image from Cluster profiler showing significantly enriched biological processes </div> <p>Let’s dive in.</p> <p>If you’ve spent time in genomics data analysis, you’ve likely encountered a list of genes you wanted to understand biologically. This is a common interest for biologists after a sequencing experiment or analysis. Overrepresentation analysis (ORA) is a frequently employed method, but it is often prone to inaccuracies due to the presence of many false positives in the results( reference in the literature). So, what exactly is overrepresentation analysis (ORA)?</p> <p>ORA aims to determine if established biological functions or gene sets are disproportionately represented in a list generated through experimentation. It involves comparing an experimentally derived gene list to a database of gene sets with known functions. The goal is to identify whether certain known biological functions are significantly overrepresented in the experimentally derived gene list. Enrichment analysis has become widely accessible, leading to the development of numerous packages and tools for simplified analysis. However, some users may input their gene lists without a suitable background gene set for comparison, potentially resulting in false positive enrichments.</p> <p>What is a background gene set?</p> <p>The choice of background genes is critical as it determines which functionally enriched gene sets might appear overrepresented in our gene list. It’s important to recognize that altering this background selection can significantly impact our analysis results.</p> <p>Let’s delve into a scenario: You conduct an RNA sequencing experiment on cancer cells, yielding a list of differentially expressed genes. For enrichment analysis, you consider two cases:</p> <ol> <li>Default Background: Using all genes in the genome as your background, you identify 500 terms with few of them related to cancer.</li> <li>User-Defined Background: Employing a user-defined background limited to genes found in cancer tissue, you now identify 300 relevant terms.</li> </ol> <blockquote> <p>This comparison highlights the impact of background gene selection on the enrichment analysis results, with the user-defined background providing a more contextually meaningful outcome. The improved relevance of terms in the second analysis is indeed primarily attributed to the choice of background genes. Using a background set that closely matches the context of your experiment, such as genes found in cancer tissue, increases the likelihood of identifying biologically meaningful enrichments.</p> </blockquote> <p>The misconception that all genes in the genome should be used as a background is a common one. Many popular tools do allow this option, and users may default to it because they might not fully understand the underlying statistical tests. Often, the desire to obtain relevant terms aligned with their hypothesis takes precedence. This underscores the importance of educating users about the significance of selecting an appropriate background gene set in enrichment analysis to ensure more meaningful and accurate results. An alternative approach, which is both useful and recommended, is to use the intersection of the genes measured in the tissue of interest and the genes annotated in the gene sets. This strategy enhances the relevance of the background gene set by focusing on genes that are actually expressed or relevant in your specific experimental context. It can lead to more precise and biologically meaningful enrichment analysis results compared to using all genes in the genome as the background.</p> <p>Another useful or proposed alternative to not using all the genes in the genome is to use an intersection of the genes measured in the tissue of interest and genes annotated in the gene sets. This post is a call to bring more awareness to understanding the concept of statistical assumption being tested before applying bioinformatics tools and software. While enrichment analysis is a common practice, the critical aspect of selecting appropriate background genes is often overlooked. This post serves as a vital reminder to maintain awareness of the underlying statistical assumptions when applying bioinformatics tools, especially in the context of enrichment analysis. This heightened awareness can lead to more accurate and meaningful scientific discoveries.</p> <p>References: <a href="https://twitter.com/mdziemann/status/1626407797939384320">Thread on twitter</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4561415/">NCBI</a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="Methods"/><summary type="html"><![CDATA[Enrichment analysis is common, but is it done properly?]]></summary></entry></feed>